{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "capital-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "southeast-summary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensorflow가 활용할 GPU가 장착되어 있는지 확인해 봅니다.\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-answer",
   "metadata": {},
   "source": [
    "데이터셋 로딩하기 (Cifar-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-involvement",
   "metadata": {},
   "source": [
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "#tfds.disable_progress_bar()   # 이 주석을 풀면 데이터셋 다운로드과정의 프로그레스바가 나타나지 않습니다.\n",
    "\n",
    "(ds_train), ds_info = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split=['train[:75%]'],\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-douglas",
   "metadata": {},
   "source": [
    "ds_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-typing",
   "metadata": {},
   "source": [
    "ds_info.features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-validation",
   "metadata": {},
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-cigarette",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "#tfds.disable_progress_bar()   # 이 주석을 풀면 데이터셋 다운로드과정의 프로그레스바가 나타나지 않습니다.\n",
    "\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'cifar10',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow 데이터셋을 로드하면 꼭 feature 정보를 확인해 보세요. \n",
    "print(ds_info.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 개수도 확인해 봅시다. \n",
    "print(tf.data.experimental.cardinality(ds_train))\n",
    "print(tf.data.experimental.cardinality(ds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_resize_img(image, label):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "    # image = tf.image.resize(image, [32, 32])\n",
    "    return tf.cast(image, tf.float32) / 255., label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_normalize_on_dataset(ds, is_test=False, batch_size=16):\n",
    "    ds = ds.map(\n",
    "        normalize_and_resize_img, \n",
    "        num_parallel_calls=1\n",
    "    )\n",
    "    ds = ds.batch(batch_size)\n",
    "    if not is_test:\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.shuffle(200)\n",
    "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-robert",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_info.features[\"label\"].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_info.features[\"label\"].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = tfds.show_examples(ds_train, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = tfds.show_examples(ds_test, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fresh-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_residual_block(input_layer,\n",
    "                    num_cnn=2, \n",
    "                    channel=64,\n",
    "                    block_num=1,\n",
    "                    kernel_size=(3,3), chunk_num=0\n",
    "                   ):\n",
    "    \n",
    "    # 입력 레이어\n",
    "    x = input_layer\n",
    "    \n",
    "    # CNN 레이어\n",
    "    for cnn_num in range(num_cnn):\n",
    "        if chunk_num!=0 and block_num==0 and cnn_num==0:\n",
    "            x = keras.layers.Conv2D(filters=channel,kernel_size=kernel_size,activation='relu',strides=2,\n",
    "                                    kernel_initializer='he_normal',padding='same',name=f'{chunk_num}_block{block_num}_conv{cnn_num}')(x)\n",
    "        else:\n",
    "            x = keras.layers.Conv2D(filters=channel,kernel_size=kernel_size,activation='relu',\n",
    "                                    kernel_initializer='he_normal',padding='same',name=f'{chunk_num}_block{block_num}_conv{cnn_num}')(x)\n",
    "        x = keras.layers.BatchNormalization(axis=3)(x)\n",
    "        if cnn_num < num_cnn-1:\n",
    "            x = keras.layers.Activation('relu')(x)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-soccer",
   "metadata": {},
   "source": [
    "resnet_input_layer = keras.layers.Input(shape=(224,224,3))   # 입력 레이어 생성\n",
    "resnet_block_output = build_residual_block(resnet_input_layer)    # VGG 블록 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-fifty",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "##### 블록 1개짜리 model 생성\n",
    "model = keras.Model(inputs=resnet_input_layer, outputs=resnet_block_output)  \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-baseline",
   "metadata": {},
   "source": [
    "2-5. Ablation Study 실습 (3) VGG Complete Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "russian-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "given-stake",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet(input_shape=(224,224,3),\n",
    "              num_block_list=[3, 4, 6, 3],\n",
    "              channel_list=[64,128,256,512],\n",
    "              num_classes=10, is_50=False): ## class for cats_n_dogs : 2\n",
    "    \n",
    "    input_layer = keras.layers.Input(shape=input_shape)  # input layer를 만들어둡니다.\n",
    "    x = input_layer\n",
    "\n",
    "    \n",
    "    ############\n",
    "    #CONV1\n",
    "    x = keras.layers.Conv2D(filters=64, kernel_size=(7,7), strides=2, name=f'conv1')(x)\n",
    "    x = keras.layers.MaxPooling2D(pool_size=(3,3), strides=2, name=f'initial_maxpooling')(x)\n",
    "    ############\n",
    "    \n",
    "    num_cnn = 2\n",
    "    \n",
    "    skip_connection= x\n",
    "\n",
    "    for i, (block, channel) in enumerate(zip(num_block_list, channel_list)):\n",
    "        for j in range(block):\n",
    "            if j!=0:\n",
    "                skip_connection=x\n",
    "            x = build_residual_block(\n",
    "                x,\n",
    "                num_cnn=num_cnn, \n",
    "                channel=channel,\n",
    "                block_num=j, chunk_num=i\n",
    "            )\n",
    "\n",
    "            print('x: ', x)\n",
    "            print('s: ', skip_connection)\n",
    "\n",
    "            print('chunk_num: {}, block_num: {}, add identity==================='.format(i, j))\n",
    "            if i==0:\n",
    "                x=tf.keras.layers.Add()([x, skip_connection])\n",
    "        print('--------------------reduce in size')\n",
    "        \n",
    "#         skip_connection= tf.keras.layers.ZeroPadding2D(padding=(1, 1))(x)\n",
    "#         if block_num!=1 and new_block==0:\n",
    "#             x = keras.layers.Conv2D(filters=channel,kernel_size=kernel_size,activation='relu',\n",
    "#                                     kernel_initializer='he_normal',padding='same', strides=2, name=f'block{block_num}_conv{cnn_num}')(x)\n",
    "            \n",
    "#         else:\n",
    "        \n",
    "\n",
    "# #         skip_connection= keras.layers.\n",
    "        \n",
    "    \n",
    "#     output = keras.layers.Flatten(name='flatten')(output)\n",
    "    output = keras.layers.Dense(1000, activation='relu', name='fc1')(x)\n",
    "    \n",
    "    model = keras.Model(\n",
    "        inputs=input_layer, \n",
    "        outputs=output\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "informative-intersection",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 54, 54, 64), dtype=tf.float32, name=None), name='batch_normalization_1/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 54, 54, 64), dtype=tf.float32, name=None), name='initial_maxpooling/MaxPool:0', description=\"created by layer 'initial_maxpooling'\")\n",
      "chunk_num: 0, block_num: 0, add identity===================\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 54, 54, 64), dtype=tf.float32, name=None), name='batch_normalization_3/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_3'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 54, 54, 64), dtype=tf.float32, name=None), name='add/add:0', description=\"created by layer 'add'\")\n",
      "chunk_num: 0, block_num: 1, add identity===================\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 54, 54, 64), dtype=tf.float32, name=None), name='batch_normalization_5/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_5'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 54, 54, 64), dtype=tf.float32, name=None), name='add_1/add:0', description=\"created by layer 'add_1'\")\n",
      "chunk_num: 0, block_num: 2, add identity===================\n",
      "--------------------reduce in size\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 27, 27, 128), dtype=tf.float32, name=None), name='batch_normalization_7/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_7'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 54, 54, 64), dtype=tf.float32, name=None), name='add_1/add:0', description=\"created by layer 'add_1'\")\n",
      "chunk_num: 1, block_num: 0, add identity===================\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 27, 27, 128), dtype=tf.float32, name=None), name='batch_normalization_9/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_9'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 27, 27, 128), dtype=tf.float32, name=None), name='batch_normalization_7/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_7'\")\n",
      "chunk_num: 1, block_num: 1, add identity===================\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 27, 27, 128), dtype=tf.float32, name=None), name='batch_normalization_11/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_11'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 27, 27, 128), dtype=tf.float32, name=None), name='batch_normalization_9/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_9'\")\n",
      "chunk_num: 1, block_num: 2, add identity===================\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 27, 27, 128), dtype=tf.float32, name=None), name='batch_normalization_13/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_13'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 27, 27, 128), dtype=tf.float32, name=None), name='batch_normalization_11/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_11'\")\n",
      "chunk_num: 1, block_num: 3, add identity===================\n",
      "--------------------reduce in size\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 256), dtype=tf.float32, name=None), name='batch_normalization_15/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_15'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 27, 27, 128), dtype=tf.float32, name=None), name='batch_normalization_11/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_11'\")\n",
      "chunk_num: 2, block_num: 0, add identity===================\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 256), dtype=tf.float32, name=None), name='batch_normalization_17/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_17'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 256), dtype=tf.float32, name=None), name='batch_normalization_15/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_15'\")\n",
      "chunk_num: 2, block_num: 1, add identity===================\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 256), dtype=tf.float32, name=None), name='batch_normalization_19/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_19'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 256), dtype=tf.float32, name=None), name='batch_normalization_17/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_17'\")\n",
      "chunk_num: 2, block_num: 2, add identity===================\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 256), dtype=tf.float32, name=None), name='batch_normalization_21/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_21'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 256), dtype=tf.float32, name=None), name='batch_normalization_19/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_19'\")\n",
      "chunk_num: 2, block_num: 3, add identity===================\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 256), dtype=tf.float32, name=None), name='batch_normalization_23/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_23'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 256), dtype=tf.float32, name=None), name='batch_normalization_21/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_21'\")\n",
      "chunk_num: 2, block_num: 4, add identity===================\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 256), dtype=tf.float32, name=None), name='batch_normalization_25/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_25'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 256), dtype=tf.float32, name=None), name='batch_normalization_23/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_23'\")\n",
      "chunk_num: 2, block_num: 5, add identity===================\n",
      "--------------------reduce in size\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 7, 7, 512), dtype=tf.float32, name=None), name='batch_normalization_27/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_27'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 256), dtype=tf.float32, name=None), name='batch_normalization_23/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_23'\")\n",
      "chunk_num: 3, block_num: 0, add identity===================\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 7, 7, 512), dtype=tf.float32, name=None), name='batch_normalization_29/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_29'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 7, 7, 512), dtype=tf.float32, name=None), name='batch_normalization_27/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_27'\")\n",
      "chunk_num: 3, block_num: 1, add identity===================\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 7, 7, 512), dtype=tf.float32, name=None), name='batch_normalization_31/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_31'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 7, 7, 512), dtype=tf.float32, name=None), name='batch_normalization_29/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_29'\")\n",
      "chunk_num: 3, block_num: 2, add identity===================\n",
      "--------------------reduce in size\n"
     ]
    }
   ],
   "source": [
    "resnet_34 = build_resnet(input_shape=(224,224,3), is_50=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "collectible-beginning",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 54, 54, 64), dtype=tf.float32, name=None), name='batch_normalization_1795/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1795'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 54, 54, 64), dtype=tf.float32, name=None), name='initial_maxpooling/MaxPool:0', description=\"created by layer 'initial_maxpooling'\")\n",
      "chunk_num: 0, block_num: 0, add identity===================\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 54, 54, 64), dtype=tf.float32, name=None), name='batch_normalization_1797/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1797'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 54, 54, 64), dtype=tf.float32, name=None), name='add_78/add:0', description=\"created by layer 'add_78'\")\n",
      "chunk_num: 0, block_num: 1, add identity===================\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 54, 54, 64), dtype=tf.float32, name=None), name='batch_normalization_1799/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1799'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 54, 54, 64), dtype=tf.float32, name=None), name='add_79/add:0', description=\"created by layer 'add_79'\")\n",
      "chunk_num: 0, block_num: 2, add identity===================\n",
      "--------------------reduce in size\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 27, 27, 128), dtype=tf.float32, name=None), name='batch_normalization_1801/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1801'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 56, 56, 64), dtype=tf.float32, name=None), name='zero_padding2d_4/Pad:0', description=\"created by layer 'zero_padding2d_4'\")\n",
      "chunk_num: 1, block_num: 0, add identity===================\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 27, 27, 128), dtype=tf.float32, name=None), name='batch_normalization_1803/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1803'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 27, 27, 128), dtype=tf.float32, name=None), name='batch_normalization_1801/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1801'\")\n",
      "chunk_num: 1, block_num: 1, add identity===================\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 27, 27, 128), dtype=tf.float32, name=None), name='batch_normalization_1805/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1805'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 27, 27, 128), dtype=tf.float32, name=None), name='batch_normalization_1803/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1803'\")\n",
      "chunk_num: 1, block_num: 2, add identity===================\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 27, 27, 128), dtype=tf.float32, name=None), name='batch_normalization_1807/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1807'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 27, 27, 128), dtype=tf.float32, name=None), name='batch_normalization_1805/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1805'\")\n",
      "chunk_num: 1, block_num: 3, add identity===================\n",
      "--------------------reduce in size\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 256), dtype=tf.float32, name=None), name='batch_normalization_1809/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1809'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 29, 29, 128), dtype=tf.float32, name=None), name='zero_padding2d_5/Pad:0', description=\"created by layer 'zero_padding2d_5'\")\n",
      "chunk_num: 2, block_num: 0, add identity===================\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 256), dtype=tf.float32, name=None), name='batch_normalization_1811/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1811'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 256), dtype=tf.float32, name=None), name='batch_normalization_1809/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1809'\")\n",
      "chunk_num: 2, block_num: 1, add identity===================\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 256), dtype=tf.float32, name=None), name='batch_normalization_1813/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1813'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 256), dtype=tf.float32, name=None), name='batch_normalization_1811/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1811'\")\n",
      "chunk_num: 2, block_num: 2, add identity===================\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 256), dtype=tf.float32, name=None), name='batch_normalization_1815/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1815'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 256), dtype=tf.float32, name=None), name='batch_normalization_1813/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1813'\")\n",
      "chunk_num: 2, block_num: 3, add identity===================\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 256), dtype=tf.float32, name=None), name='batch_normalization_1817/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1817'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 256), dtype=tf.float32, name=None), name='batch_normalization_1815/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1815'\")\n",
      "chunk_num: 2, block_num: 4, add identity===================\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 256), dtype=tf.float32, name=None), name='batch_normalization_1819/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1819'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 256), dtype=tf.float32, name=None), name='batch_normalization_1817/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1817'\")\n",
      "chunk_num: 2, block_num: 5, add identity===================\n",
      "--------------------reduce in size\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 7, 7, 512), dtype=tf.float32, name=None), name='batch_normalization_1821/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1821'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 256), dtype=tf.float32, name=None), name='zero_padding2d_6/Pad:0', description=\"created by layer 'zero_padding2d_6'\")\n",
      "chunk_num: 3, block_num: 0, add identity===================\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 7, 7, 512), dtype=tf.float32, name=None), name='batch_normalization_1823/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1823'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 7, 7, 512), dtype=tf.float32, name=None), name='batch_normalization_1821/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1821'\")\n",
      "chunk_num: 3, block_num: 1, add identity===================\n",
      "x:  KerasTensor(type_spec=TensorSpec(shape=(None, 7, 7, 512), dtype=tf.float32, name=None), name='batch_normalization_1825/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1825'\")\n",
      "s:  KerasTensor(type_spec=TensorSpec(shape=(None, 7, 7, 512), dtype=tf.float32, name=None), name='batch_normalization_1823/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1823'\")\n",
      "chunk_num: 3, block_num: 2, add identity===================\n",
      "--------------------reduce in size\n"
     ]
    }
   ],
   "source": [
    "resnet_34 = build_resnet(input_shape=(224,224,3), is_50=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "australian-cradle",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_63\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_82 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 109, 109, 64) 9472        input_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "initial_maxpooling (MaxPooling2 (None, 54, 54, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "0_block0_conv0 (Conv2D)         (None, 54, 54, 64)   36928       initial_maxpooling[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1762 (Batch (None, 54, 54, 64)   256         0_block0_conv0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_881 (Activation)     (None, 54, 54, 64)   0           batch_normalization_1762[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "0_block0_conv1 (Conv2D)         (None, 54, 54, 64)   36928       activation_881[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1763 (Batch (None, 54, 54, 64)   256         0_block0_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_75 (Add)                    (None, 54, 54, 64)   0           batch_normalization_1763[0][0]   \n",
      "                                                                 initial_maxpooling[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "0_block1_conv0 (Conv2D)         (None, 54, 54, 64)   36928       add_75[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1764 (Batch (None, 54, 54, 64)   256         0_block1_conv0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_882 (Activation)     (None, 54, 54, 64)   0           batch_normalization_1764[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "0_block1_conv1 (Conv2D)         (None, 54, 54, 64)   36928       activation_882[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1765 (Batch (None, 54, 54, 64)   256         0_block1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_76 (Add)                    (None, 54, 54, 64)   0           batch_normalization_1765[0][0]   \n",
      "                                                                 add_75[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "0_block2_conv0 (Conv2D)         (None, 54, 54, 64)   36928       add_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1766 (Batch (None, 54, 54, 64)   256         0_block2_conv0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_883 (Activation)     (None, 54, 54, 64)   0           batch_normalization_1766[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "0_block2_conv1 (Conv2D)         (None, 54, 54, 64)   36928       activation_883[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1767 (Batch (None, 54, 54, 64)   256         0_block2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_77 (Add)                    (None, 54, 54, 64)   0           batch_normalization_1767[0][0]   \n",
      "                                                                 add_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "1_block0_conv0 (Conv2D)         (None, 27, 27, 128)  73856       add_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1768 (Batch (None, 27, 27, 128)  512         1_block0_conv0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_884 (Activation)     (None, 27, 27, 128)  0           batch_normalization_1768[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "1_block0_conv1 (Conv2D)         (None, 27, 27, 128)  147584      activation_884[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1769 (Batch (None, 27, 27, 128)  512         1_block0_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "1_block1_conv0 (Conv2D)         (None, 27, 27, 128)  147584      batch_normalization_1769[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1770 (Batch (None, 27, 27, 128)  512         1_block1_conv0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_885 (Activation)     (None, 27, 27, 128)  0           batch_normalization_1770[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "1_block1_conv1 (Conv2D)         (None, 27, 27, 128)  147584      activation_885[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1771 (Batch (None, 27, 27, 128)  512         1_block1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "1_block2_conv0 (Conv2D)         (None, 27, 27, 128)  147584      batch_normalization_1771[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1772 (Batch (None, 27, 27, 128)  512         1_block2_conv0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_886 (Activation)     (None, 27, 27, 128)  0           batch_normalization_1772[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "1_block2_conv1 (Conv2D)         (None, 27, 27, 128)  147584      activation_886[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1773 (Batch (None, 27, 27, 128)  512         1_block2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "1_block3_conv0 (Conv2D)         (None, 27, 27, 128)  147584      batch_normalization_1773[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1774 (Batch (None, 27, 27, 128)  512         1_block3_conv0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_887 (Activation)     (None, 27, 27, 128)  0           batch_normalization_1774[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "1_block3_conv1 (Conv2D)         (None, 27, 27, 128)  147584      activation_887[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1775 (Batch (None, 27, 27, 128)  512         1_block3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "2_block0_conv0 (Conv2D)         (None, 14, 14, 256)  295168      batch_normalization_1775[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1776 (Batch (None, 14, 14, 256)  1024        2_block0_conv0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_888 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1776[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2_block0_conv1 (Conv2D)         (None, 14, 14, 256)  590080      activation_888[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1777 (Batch (None, 14, 14, 256)  1024        2_block0_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "2_block1_conv0 (Conv2D)         (None, 14, 14, 256)  590080      batch_normalization_1777[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1778 (Batch (None, 14, 14, 256)  1024        2_block1_conv0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_889 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1778[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2_block1_conv1 (Conv2D)         (None, 14, 14, 256)  590080      activation_889[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1779 (Batch (None, 14, 14, 256)  1024        2_block1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "2_block2_conv0 (Conv2D)         (None, 14, 14, 256)  590080      batch_normalization_1779[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1780 (Batch (None, 14, 14, 256)  1024        2_block2_conv0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_890 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1780[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2_block2_conv1 (Conv2D)         (None, 14, 14, 256)  590080      activation_890[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1781 (Batch (None, 14, 14, 256)  1024        2_block2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "2_block3_conv0 (Conv2D)         (None, 14, 14, 256)  590080      batch_normalization_1781[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1782 (Batch (None, 14, 14, 256)  1024        2_block3_conv0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_891 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1782[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2_block3_conv1 (Conv2D)         (None, 14, 14, 256)  590080      activation_891[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1783 (Batch (None, 14, 14, 256)  1024        2_block3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "2_block4_conv0 (Conv2D)         (None, 14, 14, 256)  590080      batch_normalization_1783[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1784 (Batch (None, 14, 14, 256)  1024        2_block4_conv0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_892 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1784[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2_block4_conv1 (Conv2D)         (None, 14, 14, 256)  590080      activation_892[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1785 (Batch (None, 14, 14, 256)  1024        2_block4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "2_block5_conv0 (Conv2D)         (None, 14, 14, 256)  590080      batch_normalization_1785[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1786 (Batch (None, 14, 14, 256)  1024        2_block5_conv0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_893 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1786[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2_block5_conv1 (Conv2D)         (None, 14, 14, 256)  590080      activation_893[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1787 (Batch (None, 14, 14, 256)  1024        2_block5_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "3_block0_conv0 (Conv2D)         (None, 7, 7, 512)    1180160     batch_normalization_1787[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1788 (Batch (None, 7, 7, 512)    2048        3_block0_conv0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_894 (Activation)     (None, 7, 7, 512)    0           batch_normalization_1788[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "3_block0_conv1 (Conv2D)         (None, 7, 7, 512)    2359808     activation_894[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1789 (Batch (None, 7, 7, 512)    2048        3_block0_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "3_block1_conv0 (Conv2D)         (None, 7, 7, 512)    2359808     batch_normalization_1789[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1790 (Batch (None, 7, 7, 512)    2048        3_block1_conv0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_895 (Activation)     (None, 7, 7, 512)    0           batch_normalization_1790[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "3_block1_conv1 (Conv2D)         (None, 7, 7, 512)    2359808     activation_895[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1791 (Batch (None, 7, 7, 512)    2048        3_block1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "3_block2_conv0 (Conv2D)         (None, 7, 7, 512)    2359808     batch_normalization_1791[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1792 (Batch (None, 7, 7, 512)    2048        3_block2_conv0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_896 (Activation)     (None, 7, 7, 512)    0           batch_normalization_1792[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "3_block2_conv1 (Conv2D)         (None, 7, 7, 512)    2359808     activation_896[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1793 (Batch (None, 7, 7, 512)    2048        3_block2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 7, 7, 1000)   513000      batch_normalization_1793[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 21,646,440\n",
      "Trainable params: 21,631,336\n",
      "Non-trainable params: 15,104\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_34.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-equipment",
   "metadata": {},
   "source": [
    "2) VGG-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "muslim-literacy",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_vgg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-216-ad0d349518aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 원하는 블록의 설계에 따라 매개변수로 리스트를 전달해 줍니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m vgg_19 = build_vgg(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mnum_cnn_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mchannel_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'build_vgg' is not defined"
     ]
    }
   ],
   "source": [
    "# 원하는 블록의 설계에 따라 매개변수로 리스트를 전달해 줍니다.\n",
    "vgg_19 = build_vgg(\n",
    "    num_cnn_list=[2,2,4,4,4],\n",
    "    channel_list=[64,128,256,512,512]\n",
    ")\n",
    "\n",
    "vgg_19.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-humanitarian",
   "metadata": {},
   "source": [
    "2-6. Ablation Study 실습 (4) VGG-16 vs VGG-19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-navigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'cifar10',\n",
    "    split=['train', 'test'],\n",
    "    as_supervised=True,\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    ")\n",
    "ds_train = apply_normalize_on_dataset(ds_train, batch_size=BATCH_SIZE)\n",
    "ds_test = apply_normalize_on_dataset(ds_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_16.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(lr=0.01, clipnorm=1.),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_16 = vgg_16.fit(\n",
    "    ds_train,\n",
    "    steps_per_epoch=int(ds_info.splits['train'].num_examples/BATCH_SIZE),\n",
    "    validation_steps=int(ds_info.splits['test'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_19.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(lr=0.01, clipnorm=1.),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_19 = vgg_19.fit(\n",
    "    ds_train,\n",
    "    steps_per_epoch=int(ds_info.splits['train'].num_examples/BATCH_SIZE),\n",
    "    validation_steps=int(ds_info.splits['test'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-carnival",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history_16.history['loss'], 'r')\n",
    "plt.plot(history_19.history['loss'], 'b')\n",
    "plt.title('Model training loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['vgg_16', 'vgg_19'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_16.history['val_accuracy'], 'r')\n",
    "plt.plot(history_19.history['val_accuracy'], 'b')\n",
    "plt.title('Model validation accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['vgg_16', 'vgg_19'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-secondary",
   "metadata": {},
   "source": [
    "2-7. 프로젝트: ResNet Ablation Study\n",
    "1) ResNet 기본 블록 구성하기\n",
    "이제 실전으로 돌아와서 ResNet-34와 ResNet-50 네트워크를 직접 만든다고 생각해 봅시다. 우선 ResNet-34와 ResNet-50에서 사용되는 블록의 공통점을 찾고 차이점을 찾아봅시다.\n",
    "\n",
    "Deep Residual Learning for Image Recognition(paper)\n",
    "빛과 같은 카이밍허님의 깃헙\n",
    "content img\n",
    "Q1. ResNet논문에 소개된 위 표에서, ResNet 34와 50에서 사용된 블록들의 공통점과 차이점을 비교해보고 그 특징을 정리해봅시다.\n",
    "\n",
    ".\n",
    "예시답안\n",
    "예시답안\n",
    "ResNet-34와 ResNet-50은 모두 conv block이라고 불리는 블록 구조를 각각 3, 4, 6, 3개씩 반복해서 쌓은 형태라는 공통점을 가지고 있습니다. 그러나 ResNet-34와 ResNet-50의 블록 내부 구성은 약간 다릅니다. ResNet-34의 경우 Block은 3x3 kernel인 Convolution layer로만 구성되어있지만, ResNet-50은 1x1 Convolution이 앞뒤로 붙어 더 많은 레이어를 한 블록 내에 가지게 됩니다.\n",
    "\n",
    "위의 퀴즈의 답을 어느 정도 스스로 찾아내셨다면 ResNet의 기본 블록, 또는 Residual 블록(residual block)이 어떻게 구성되어야 할지 감이 오셨을 것입니다. Learning by Doing 이라고 하죠! 이번에는 ResNet의 블록을 직접 만들어 봅시다! 혹시나 모델 내의 앞과 뒤에서 반복되지 않을 것 같은 부분은 함수로 구현하지 않아도 됩니다.\n",
    "\n",
    "우리가 지금 만들어야 하는 것은 블록을 생성하는 함수입니다. 처음이라 너무 막연하실 수 있겠지만 여러분들은 이미 몇 번의 경험이 있습니다.\n",
    "일단은 VGG에서도 블록을 생성하는 함수를 만들었습니다. ResNet이라 하더라도 아이디어의 기본 원리는 다르지 않습니다.\n",
    "\n",
    "그리고, 여러분들은 아마 이전에 VGG-16이나 ResNet-50 모델을 만들어서 훈련까지 시켜본 경험들이 있으실 것입니다. 코드를 스스로 구현한 것이 아니라 공개된 오픈소스를 활용해서 빠르게 구성했겠지만, 블록 생성 함수가 어떤 형태로 만들어지는지를 이미 경험해 보신 바 있을 테니 그것을 참고하셔도 도움이 될 것입니다.\n",
    "\n",
    "하지만 이번 단계에서는 가급적 ResNet 논문을 통해서 구현 방법에 대한 정보를 얻으시기를 권합니다. 논문만 보고 스스로 구현해 보는 경험을 통해 딥러닝 개발자로서의 내공과 자신감이 다져지게 될 것입니다.\n",
    "\n",
    "2) ResNet-34, ResNet-50 Complete Model\n",
    "ResNet 모델 구현 시 Sequential API나 Subclass API를 사용한다면, 그 과정에서 모델 단위로 기존의 코드를 재활용했을 때 model.summary() 호출 시 서브모델 내부의 레이어 구성이 생략되고 서브모델 단위로만 출력될 우려가 있습니다. 모델 구성만을 위해서는 그런 방법도 무방하지만, 가급적 이번 실습에서는 VGG 실습 예시에서처럼 Functional API 를 구성하는 방식을 사용할 것을 권합니다.\n",
    "\n",
    "ResNet-34\n",
    "VGG와 같이 블록을 만드는 함수를 사용해서 직접 전체 모델을 만들어 봅시다. ResNet-34와 ResNet-50의 차이에 따라 달라지는 구성(configuration)을 함수에 전달해서 같은 생성 함수 build_resnet()를 통해서 ResNet의 여러 가지 버전들을 모두 만들어 낼 수 있도록 해야 합니다.\n",
    "\n",
    "다음의 코드를 실행하면,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-narrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_50 = build_resnet(input_shape=(32, 32,3), is_50=True)\n",
    "resnet_50.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-instrument",
   "metadata": {},
   "source": [
    "이러한 결과와 '비슷'하게 나와야 합니다. 참고하세요!\n",
    "ResNet-50은 구현마다 약간씩 다르게 나올 수 있습니다. 왜냐하면 Residual 블록의 Batch Normalization과 ReLU 레이어의 위치가 논문에 명시되지 않았기 때문이죠!\n",
    "\n",
    "하지만 ResNet을 고안한 4인방은 이에 대해 또 한번 논문을 씁니다. Residual 블록에 대해서 자세하게 씁니다. 이 논문을 읽어보면 오리지널 ResNet-50에 대한 힌트가 약.간. 있을 수도 있습니다~!\n",
    "\n",
    "Identity Mappings in Deep Residual Networks\n",
    "\n",
    "3) 일반 네트워크(plain network) 만들기\n",
    "블록 코드 수정하기\n",
    "우리는 앞에서 ResNet 모델을 구현했습니다. ResNet의 핵심 아이디어는 skip connection과 residual network기 때문에, ResNet의 효과를 보여주기 위해서는 skip connection이 없는 일반 네트워크(plain net)가 필요합니다. 위에서 ResNet 블록을 만들기 위한 함수를 그대로 활용해서 skip connection이 없는 블록을 만들 수 있도록 기능을 추가해 주세요!\n",
    "\n",
    "전체 함수 코드 수정하기\n",
    "이제 위에서 만든 블록 함수를 토대로 전체 네트워크를 만들 수 있도록 전체 네트워크 코드를 수정합시다. ResNet-50과 ResNet-34, 그리고 같은 레이어를 가지지만 skip connection이 없는 PlainNet-50과 PlainNet-34를 만들 수 있는 함수 build_plainnet()를 만들어 보세요. 이때 입력 이미지의 크기는 (224, 224, 3)으로 해주세요.\n",
    "\n",
    "4) ResNet-50 vs Plain-50 또는 ResNet-34 vs Plain-34\n",
    "Ablation Study\n",
    "이제 VGG-16, 19 예제와 같이 ResNet-50 vs Plain-50 또는 ResNet-34 vs Plain-34에 대해서 학습을 진행해 봅니다. 그리고 결과를 비교해 봅시다! ResNet은 많은 레이어와 Pooling을 거치므로 CIFAR-10에서는 오버피팅(overfitting)으로 잘 동작하지 않을 수 있습니다. 레이어가 많고 학습해야 할 변수(parameter)가 많은 데 비해, 데이터 수가 많지 않기 때문이지요. 224x224 픽셀 크기의 데이터셋을 찾아서 실험해 보도록 합시다. 학습은 끝까지 시키기엔 시간이 없으니 확인을 위한 정도의 epoch로 설정해 주세요.\n",
    "\n",
    "어떤 데이터셋을 사용하셔도 무방하지만, 얼른 떠오르는 것이 없다면 tensorflow-datasets에서 제공하는 cats_vs_dogs 데이터셋을 추천합니다. 아마 이 데이터셋도 다루어 보신 적이 있을 것입니다. Tensorflow에서 제공하는 데이터셋이므로 오늘 VGG 학습에 사용했던 CIFAR-10을 로딩하는 것과 같은 방법으로 활용하실 수 있습니다.\n",
    "\n",
    "시각화\n",
    "학습을 통해 만들어진 history를 matplotlib로 시각화하여 두 모델의 검증 정확도(validation accuracy)와 검증 손실(validation loss)이 어떻게 다른지 살펴봅시다.\n",
    "\n",
    "추가 실험\n",
    "시간이 남으면 아래 카탈로그를 보고, tensorflow-datasets의 지원하는 다른 데이터셋에 실험을 해봅시다.\n",
    "\n",
    "Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-macedonia",
   "metadata": {},
   "source": [
    "루브릭\n",
    "\n",
    "아래의 기준을 바탕으로 프로젝트를 평가합니다.\n",
    "\n",
    "평가문항\t상세기준\n",
    "1. ResNet-34, ResNet-50 모델 구현이 정상적으로 진행되었는가?\n",
    "\n",
    "블록함수 구현이 제대로 진행되었으며 구현한 모델의 summary가 예상된 형태로 출력되었다.\n",
    "2. 구현한 ResNet 모델을 활용하여 Image Classification 모델 훈련이 가능한가?\n",
    "\n",
    "cats_vs_dogs 데이터셋으로 학습시 몇 epoch동안 안정적으로 loss 감소가 진행 확인되었다.\n",
    "3. Ablation Study 결과가 바른 포맷으로 제출되었는가?\n",
    "\n",
    "ResNet-34, ResNet-50 각각 plain모델과 residual모델을 동일한 epoch만큼 학습시켰을 때의 validation accuracy 기준으로 Ablation Study 결과표가 작성되었다.\n",
    "프로젝트 업로드 (URL)\n",
    "\n",
    "GitHub URL을 입력하신 후 하단의 [성취하기] 버튼을 눌러주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-homeless",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-ultimate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-offering",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-vintage",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
