{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "valuable-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "every-calendar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensorflow가 활용할 GPU가 장착되어 있는지 확인해 봅니다.\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-payroll",
   "metadata": {},
   "source": [
    "데이터셋 로딩하기 (Cifar-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-guidance",
   "metadata": {},
   "source": [
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "#tfds.disable_progress_bar()   # 이 주석을 풀면 데이터셋 다운로드과정의 프로그레스바가 나타나지 않습니다.\n",
    "\n",
    "(ds_train), ds_info = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split=['train[:75%]'],\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-hamburg",
   "metadata": {},
   "source": [
    "ds_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-switch",
   "metadata": {},
   "source": [
    "ds_info.features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-spread",
   "metadata": {},
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-plumbing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "#tfds.disable_progress_bar()   # 이 주석을 풀면 데이터셋 다운로드과정의 프로그레스바가 나타나지 않습니다.\n",
    "\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'cifar10',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-christopher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow 데이터셋을 로드하면 꼭 feature 정보를 확인해 보세요. \n",
    "print(ds_info.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 개수도 확인해 봅시다. \n",
    "print(tf.data.experimental.cardinality(ds_train))\n",
    "print(tf.data.experimental.cardinality(ds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-register",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_resize_img(image, label):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "    # image = tf.image.resize(image, [32, 32])\n",
    "    return tf.cast(image, tf.float32) / 255., label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-biotechnology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_normalize_on_dataset(ds, is_test=False, batch_size=16):\n",
    "    ds = ds.map(\n",
    "        normalize_and_resize_img, \n",
    "        num_parallel_calls=1\n",
    "    )\n",
    "    ds = ds.batch(batch_size)\n",
    "    if not is_test:\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.shuffle(200)\n",
    "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-action",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_info.features[\"label\"].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_info.features[\"label\"].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-forest",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = tfds.show_examples(ds_train, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = tfds.show_examples(ds_test, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "funded-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_resnet(input_shape=(224,224,3),\n",
    "#               num_block_list=[3, 4, 6, 3],\n",
    "#               channel_list=[64,128,256,512],\n",
    "#               num_classes=10, is_50=False): ## class for cats_n_dogs : 2\n",
    "    \n",
    "#     input_layer = keras.layers.Input(shape=input_shape)  # input layer를 만들어둡니다.\n",
    "#     x = input_layer\n",
    "\n",
    "    \n",
    "#     ############\n",
    "#     #CONV1\n",
    "#     x = keras.layers.Conv2D(filters=64, kernel_size=(7,7), strides=2, name=f'conv1')(x)\n",
    "#     x = keras.layers.MaxPooling2D(pool_size=(3,3), strides=2, name=f'initial_maxpooling')(x)\n",
    "#     ############\n",
    "    \n",
    "#     num_cnn = 2\n",
    "    \n",
    "#     skip_connection= x\n",
    "\n",
    "#     for i, (block, channel) in enumerate(zip(num_block_list, channel_list)):\n",
    "#         for j in range(block):\n",
    "#             if j!=0:\n",
    "#                 skip_connection=x\n",
    "#             x = build_residual_block(\n",
    "#                 x,\n",
    "#                 num_cnn=num_cnn, \n",
    "#                 channel=channel,\n",
    "#                 block_num=j, chunk_num=i\n",
    "#             )\n",
    "\n",
    "#             print('x: ', x)\n",
    "#             print('s: ', skip_connection)\n",
    "\n",
    "#             print('chunk_num: {}, block_num: {}, add identity==================='.format(i, j))\n",
    "#             if i==0:\n",
    "#                 x=tf.keras.layers.Add()([x, skip_connection])\n",
    "#         print('--------------------reduce in size')\n",
    "        \n",
    "#     output = keras.layers.Dense(1000, activation='relu', name='fc1')(x)\n",
    "    \n",
    "#     model = keras.Model(\n",
    "#         inputs=input_layer, \n",
    "#         outputs=output\n",
    "#     )\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-absorption",
   "metadata": {},
   "source": [
    "RESNET CONV BLOCK DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "synthetic-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(input_layer, num_cnn, block_num, input_shape=(224,224,3), is_50=False):\n",
    "    channel=64\n",
    "    kernel_size=(3,3)\n",
    "    x = input_layer\n",
    "    \n",
    "    for i, cnn_num in enumerate(range(num_cnn)):\n",
    "        if i==0 and block_num>0:\n",
    "            x = keras.layers.Conv2D(filters=channel, kernel_size=kernel_size, padding='same', activation='relu', strides=2, \n",
    "                                    kernel_initializer='he_normal')(x)\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "        else:\n",
    "            x = keras.layers.Conv2D(filters=channel, kernel_size=kernel_size,# activation='relu',\n",
    "                                    kernel_initializer='he_normal',padding='same')(x)\n",
    "        \n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.activations.relu(x, alpha=0.0, max_value=None, threshold=0)\n",
    "\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "played-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet(input_layer, is_50=False):\n",
    "    \n",
    "    num_cnn_list=[3, 4, 6, 3]\n",
    "    channel_list=[64,128, 256, 512]\n",
    "\n",
    "    x= input_layer\n",
    "    \n",
    "    \n",
    "    ############\n",
    "    #CONV1\n",
    "    x = keras.layers.Conv2D(filters=64, kernel_size=(7,7), strides=2, padding='same', name=f'conv1')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = keras.layers.MaxPooling2D(pool_size=(3,3), padding='same', strides=2, name=f'initial_maxpooling')(x)\n",
    "    ############\n",
    "\n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        x = convolutional_block(x, num_cnn, i, input_shape=(224,224,3), is_50=False)\n",
    "\n",
    "    \n",
    "    x= keras.layers.Dense(1000, activation='softmax')(x)\n",
    "    \n",
    "    model= keras.Model(inputs= input_layer, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "phantom-wages",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_39 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 64)      9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_158 (Bat (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "initial_maxpooling (MaxPooli (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_350 (Conv2D)          (None, 56, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_159 (Bat (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_106 (TFOpLambda)  (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_351 (Conv2D)          (None, 56, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_160 (Bat (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_107 (TFOpLambda)  (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_352 (Conv2D)          (None, 56, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_161 (Bat (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_108 (TFOpLambda)  (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_353 (Conv2D)          (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_162 (Bat (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_354 (Conv2D)          (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_163 (Bat (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_109 (TFOpLambda)  (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_355 (Conv2D)          (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_164 (Bat (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_110 (TFOpLambda)  (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_356 (Conv2D)          (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_165 (Bat (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_111 (TFOpLambda)  (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_357 (Conv2D)          (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_166 (Bat (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_358 (Conv2D)          (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_167 (Bat (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_112 (TFOpLambda)  (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_359 (Conv2D)          (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_168 (Bat (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_113 (TFOpLambda)  (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_360 (Conv2D)          (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_169 (Bat (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_114 (TFOpLambda)  (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_361 (Conv2D)          (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_170 (Bat (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_115 (TFOpLambda)  (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_362 (Conv2D)          (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_171 (Bat (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_116 (TFOpLambda)  (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_363 (Conv2D)          (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_172 (Bat (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_364 (Conv2D)          (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_173 (Bat (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_117 (TFOpLambda)  (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_365 (Conv2D)          (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_174 (Bat (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_118 (TFOpLambda)  (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 7, 7, 1000)        65000     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 7, 7, 1000)        1001000   \n",
      "=================================================================\n",
      "Total params: 1,670,672\n",
      "Trainable params: 1,668,496\n",
      "Non-trainable params: 2,176\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape=(224,224,3)\n",
    "input_layer = keras.layers.Input(shape=input_shape)  # input layer를 만들어둡니다.\n",
    "\n",
    "resnet_34 = build_resnet(input_layer, is_50=False)\n",
    "resnet_34.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-tennis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-devices",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "shaped-sailing",
   "metadata": {},
   "source": [
    "CHANNEL ADDED (channel * 2 -> shape / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "sophisticated-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(input_layer, num_cnn, channel, block_num, input_shape=(224,224,3), is_50=False):\n",
    "    kernel_size=(3,3)\n",
    "    x = input_layer\n",
    "    \n",
    "    skip_connection= x\n",
    "    \n",
    "    \n",
    "    for i, cnn_num in enumerate(range(num_cnn)):\n",
    "        if i==0 and block_num>0:\n",
    "            x = keras.layers.Conv2D(filters=channel, kernel_size=kernel_size, activation='relu', strides=2,\n",
    "                                    kernel_initializer='he_normal')(x)\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "        else:\n",
    "            x = keras.layers.Conv2D(filters=channel, kernel_size=kernel_size,# activation='relu',\n",
    "                                    kernel_initializer='he_normal',padding='same')(x)\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.activations.relu(x, alpha=0.0, max_value=None, threshold=0)\n",
    "\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "developing-contrast",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-104-0aaddd826afd>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-104-0aaddd826afd>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    x = keras.layers.MaxPooling2D(pool_size=(3,3), padding='same' strides=2, name=f'initial_maxpooling')(x)\u001b[0m\n\u001b[0m                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def build_resnet(input_layer, is_50=False):\n",
    "    num_cnn_list=[3, 4, 6, 3]\n",
    "    channel_list=[64,128, 256, 512]\n",
    "\n",
    "    x= input_layer\n",
    "    \n",
    "    \n",
    "    ############\n",
    "    #CONV1\n",
    "    x = keras.layers.Conv2D(filters=64, kernel_size=(7,7), strides=2, padding='same', name=f'conv1')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = keras.layers.MaxPooling2D(pool_size=(3,3), padding='same' strides=2, name=f'initial_maxpooling')(x)\n",
    "    ############\n",
    "\n",
    "    skipconnection= x\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        print(i, num_cnn, channel)\n",
    "        x = convolutional_block(x, num_cnn, channel, i, input_shape=(224,224,3), is_50=False)\n",
    "\n",
    "    x= keras.layers.Dense(1000, activation='relu')(x)\n",
    "    model= keras.Model(inputs= input_layer, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cordless-punishment",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 64\n",
      "1 4 128\n",
      "2 6 256\n",
      "3 3 512\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_35 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 64)      9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_90 (Batc (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "initial_maxpooling (MaxPooli (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_286 (Conv2D)          (None, 55, 55, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_91 (Batc (None, 55, 55, 64)        256       \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_54 (TFOpLambda)   (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_287 (Conv2D)          (None, 55, 55, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc (None, 55, 55, 64)        256       \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_55 (TFOpLambda)   (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_288 (Conv2D)          (None, 55, 55, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_93 (Batc (None, 55, 55, 64)        256       \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_56 (TFOpLambda)   (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_289 (Conv2D)          (None, 27, 27, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 27, 27, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_290 (Conv2D)          (None, 27, 27, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 27, 27, 128)       512       \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_57 (TFOpLambda)   (None, 27, 27, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_291 (Conv2D)          (None, 27, 27, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_96 (Batc (None, 27, 27, 128)       512       \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_58 (TFOpLambda)   (None, 27, 27, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_292 (Conv2D)          (None, 27, 27, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_97 (Batc (None, 27, 27, 128)       512       \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_59 (TFOpLambda)   (None, 27, 27, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_293 (Conv2D)          (None, 13, 13, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_98 (Batc (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_294 (Conv2D)          (None, 13, 13, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_99 (Batc (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_60 (TFOpLambda)   (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_295 (Conv2D)          (None, 13, 13, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_100 (Bat (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_61 (TFOpLambda)   (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_296 (Conv2D)          (None, 13, 13, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_101 (Bat (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_62 (TFOpLambda)   (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_297 (Conv2D)          (None, 13, 13, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_102 (Bat (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_63 (TFOpLambda)   (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_298 (Conv2D)          (None, 13, 13, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_103 (Bat (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_64 (TFOpLambda)   (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_299 (Conv2D)          (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_104 (Bat (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_300 (Conv2D)          (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_105 (Bat (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_65 (TFOpLambda)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_301 (Conv2D)          (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_106 (Bat (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_66 (TFOpLambda)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 6, 6, 1000)        513000    \n",
      "=================================================================\n",
      "Total params: 10,310,568\n",
      "Trainable params: 10,302,888\n",
      "Non-trainable params: 7,680\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape=(224,224,3)\n",
    "input_layer = keras.layers.Input(shape=input_shape)  # input layer를 만들어둡니다.\n",
    "\n",
    "resnet_34 = build_resnet(input_layer, is_50=False)\n",
    "resnet_34.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-america",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-switch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-audit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-router",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "correct-skating",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(input_layer, num_cnn, channel, block_num, input_shape=(224,224,3), is_50=False):\n",
    "    kernel_size=(3,3)\n",
    "    x = input_layer\n",
    "    \n",
    "    skip_connection= x\n",
    "    \n",
    "    \n",
    "    for i, cnn_num in enumerate(range(num_cnn)):\n",
    "        if i==0 and block_num>0:\n",
    "            x = keras.layers.Conv2D(filters=channel, kernel_size=kernel_size, activation='relu', strides=2,\n",
    "                                    kernel_initializer='he_normal')(x)\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "        else:\n",
    "            x = keras.layers.Conv2D(filters=channel, kernel_size=kernel_size,# activation='relu',\n",
    "                                    kernel_initializer='he_normal',padding='same')(x)\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.activations.relu(x, alpha=0.0, max_value=None, threshold=0)\n",
    "\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "entitled-copying",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet(input_layer, is_50=False):\n",
    "    num_cnn_list=[3, 4, 6, 3]\n",
    "    channel_list=[64,128, 256, 512]\n",
    "\n",
    "    x= input_layer\n",
    "    \n",
    "    \n",
    "    ############\n",
    "    #CONV1\n",
    "    x = keras.layers.Conv2D(filters=64, kernel_size=(7,7), strides=2, padding='same', name=f'conv1')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = keras.layers.MaxPooling2D(pool_size=(3,3), strides=2, name=f'initial_maxpooling')(x)\n",
    "    ############\n",
    "\n",
    "    skipconnection= x\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        print(i, num_cnn, channel)\n",
    "        x = convolutional_block(x, num_cnn, channel, i, input_shape=(224,224,3), is_50=False)\n",
    "\n",
    "    x= keras.layers.Dense(1000, activation='relu')(x)\n",
    "    model= keras.Model(inputs= input_layer, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "sticky-mentor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 64\n",
      "1 4 128\n",
      "2 6 256\n",
      "3 3 512\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_35 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 64)      9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_90 (Batc (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "initial_maxpooling (MaxPooli (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_286 (Conv2D)          (None, 55, 55, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_91 (Batc (None, 55, 55, 64)        256       \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_54 (TFOpLambda)   (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_287 (Conv2D)          (None, 55, 55, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc (None, 55, 55, 64)        256       \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_55 (TFOpLambda)   (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_288 (Conv2D)          (None, 55, 55, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_93 (Batc (None, 55, 55, 64)        256       \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_56 (TFOpLambda)   (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_289 (Conv2D)          (None, 27, 27, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 27, 27, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_290 (Conv2D)          (None, 27, 27, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 27, 27, 128)       512       \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_57 (TFOpLambda)   (None, 27, 27, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_291 (Conv2D)          (None, 27, 27, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_96 (Batc (None, 27, 27, 128)       512       \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_58 (TFOpLambda)   (None, 27, 27, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_292 (Conv2D)          (None, 27, 27, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_97 (Batc (None, 27, 27, 128)       512       \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_59 (TFOpLambda)   (None, 27, 27, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_293 (Conv2D)          (None, 13, 13, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_98 (Batc (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_294 (Conv2D)          (None, 13, 13, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_99 (Batc (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_60 (TFOpLambda)   (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_295 (Conv2D)          (None, 13, 13, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_100 (Bat (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_61 (TFOpLambda)   (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_296 (Conv2D)          (None, 13, 13, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_101 (Bat (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_62 (TFOpLambda)   (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_297 (Conv2D)          (None, 13, 13, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_102 (Bat (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_63 (TFOpLambda)   (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_298 (Conv2D)          (None, 13, 13, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_103 (Bat (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_64 (TFOpLambda)   (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_299 (Conv2D)          (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_104 (Bat (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_300 (Conv2D)          (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_105 (Bat (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_65 (TFOpLambda)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_301 (Conv2D)          (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_106 (Bat (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_66 (TFOpLambda)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 6, 6, 1000)        513000    \n",
      "=================================================================\n",
      "Total params: 10,310,568\n",
      "Trainable params: 10,302,888\n",
      "Non-trainable params: 7,680\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape=(224,224,3)\n",
    "input_layer = keras.layers.Input(shape=input_shape)  # input layer를 만들어둡니다.\n",
    "\n",
    "resnet_34 = build_resnet(input_layer, is_50=False)\n",
    "resnet_34.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-convert",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-montgomery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-diversity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "described-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(input_layer, num_cnn, channel,block_num, input_shape=(224,224,3), is_50=False):\n",
    "    kernel_size=(3,3)\n",
    "    x = input_layer\n",
    "    \n",
    "    skip_connection= keras.layers.Conv2D(filters= channel, kernel_size= kernel_size)(x)\n",
    "    \n",
    "    \n",
    "    for i, cnn_num in enumerate(range(num_cnn)):\n",
    "#         pdb.set_trace()\n",
    "        if i==0 and block_num>0:\n",
    "            x = keras.layers.Conv2D(filters=channel, kernel_size=kernel_size, activation='relu', strides=2,\n",
    "                                    kernel_initializer='he_normal')(x)\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "        else:\n",
    "            x = keras.layers.Conv2D(filters=channel, kernel_size=kernel_size,# activation='relu',\n",
    "                                    kernel_initializer='he_normal',padding='same')(x)\n",
    "            x= tf.keras.layers.Add()([x, skip_connection])\n",
    "        \n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.activations.relu(x, alpha=0.0, max_value=None, threshold=0)\n",
    "\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "special-fundamental",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet(input_layer, is_50=False):\n",
    "# def build_resnet(input_shape=(32,32,3), is_50=False):\n",
    "#     input_layer = keras.layers.Input(shape=input_shape)  # input layer를 만들어둡니다.\n",
    "    \n",
    "    num_cnn_list=[3, 4, 6, 3]\n",
    "    channel_list=[64,128, 256, 512]\n",
    "\n",
    "    x= input_layer\n",
    "    \n",
    "    \n",
    "    ############\n",
    "    #CONV1\n",
    "    x = keras.layers.Conv2D(filters=64, kernel_size=(7,7), strides=2, padding='same', name=f'conv1')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = keras.layers.MaxPooling2D(pool_size=(3,3), strides=2, name=f'initial_maxpooling')(x)\n",
    "    ############\n",
    "\n",
    "    skipconnection= x\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        print(i, num_cnn, channel)\n",
    "        x = convolutional_block(x, num_cnn, channel, i, input_shape=(224,224,3), is_50=False)\n",
    "\n",
    "    x= keras.layers.Dense(1000, activation='relu')(x)\n",
    "    model= keras.Model(inputs= input_layer, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "organized-recipient",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Operands could not be broadcast together with shapes (55, 55, 64) (53, 53, 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-bb1538174eb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# input layer를 만들어둡니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresnet_34\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_resnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_50\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mresnet_34\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-90-cad8e64bcf43>\u001b[0m in \u001b[0;36mbuild_resnet\u001b[0;34m(input_layer, is_50)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_cnn_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvolutional_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_50\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-5340f2e1c997>\u001b[0m in \u001b[0;36mconvolutional_block\u001b[0;34m(input_layer, num_cnn, channel, block_num, input_shape, is_50)\u001b[0m\n\u001b[1;32m     15\u001b[0m             x = keras.layers.Conv2D(filters=channel, kernel_size=kernel_size,# activation='relu',\n\u001b[1;32m     16\u001b[0m                                     kernel_initializer='he_normal',padding='same')(x)\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_connection\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    860\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2708\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2709\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2710\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2711\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2712\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    110\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m       \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_elemwise_op_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0;31m# If the inputs have different ranks, we have to reshape them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m# to make them broadcastable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py\u001b[0m in \u001b[0;36m_compute_elemwise_op_output_shape\u001b[0;34m(self, shape1, shape2)\u001b[0m\n\u001b[1;32m     83\u001b[0m           raise ValueError(\n\u001b[1;32m     84\u001b[0m               \u001b[0;34m'Operands could not be broadcast '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m               'together with shapes ' + str(shape1) + ' ' + str(shape2))\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0moutput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Operands could not be broadcast together with shapes (55, 55, 64) (53, 53, 64)"
     ]
    }
   ],
   "source": [
    "input_shape=(224,224,3)\n",
    "input_layer = keras.layers.Input(shape=input_shape)  # input layer를 만들어둡니다.\n",
    "\n",
    "resnet_34 = build_resnet(input_layer, is_50=False)\n",
    "resnet_34.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-disclosure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-second",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-secondary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cnn_list=[3, 4, 6, 3]\n",
    "channel_list=[64,128, 256, 512]\n",
    "for num_cnn, channel in zip(num_cnn_list, channel_list):\n",
    "    print(num_cnn, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-somewhere",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(input_layer, num_cnn=2, channel=64, kernel_size=(3,3)):\n",
    "    num_blocks=4\n",
    "    \n",
    "    x= input_layer\n",
    "    skip_connection= x\n",
    "    for num_block in range(num_blocks):\n",
    "        layer_block= convolutional_block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_residual_block(input_layer,\n",
    "                    num_cnn=2, \n",
    "                    channel=64,\n",
    "                    block_num=1,\n",
    "                    kernel_size=(3,3), chunk_num=0\n",
    "                   ):\n",
    "    \n",
    "    # 입력 레이어\n",
    "    x = input_layer\n",
    "    \n",
    "    # CNN 레이어\n",
    "    for cnn_num in range(num_cnn):\n",
    "        if chunk_num!=0 and block_num==0 and cnn_num==0:\n",
    "            x = keras.layers.Conv2D(filters=channel,kernel_size=kernel_size,activation='relu',strides=2,\n",
    "                                    kernel_initializer='he_normal',padding='same',name=f'{chunk_num}_block{block_num}_conv{cnn_num}')(x)\n",
    "        else:\n",
    "            x = keras.layers.Conv2D(filters=channel,kernel_size=kernel_size,activation='relu',\n",
    "                                    kernel_initializer='he_normal',padding='same',name=f'{chunk_num}_block{block_num}_conv{cnn_num}')(x)\n",
    "        x = keras.layers.BatchNormalization(axis=3)(x)\n",
    "        if cnn_num < num_cnn-1:\n",
    "            x = keras.layers.Activation('relu')(x)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-savage",
   "metadata": {},
   "source": [
    "resnet_input_layer = keras.layers.Input(shape=(224,224,3))   # 입력 레이어 생성\n",
    "resnet_block_output = build_residual_block(resnet_input_layer)    # VGG 블록 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-massage",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "##### 블록 1개짜리 model 생성\n",
    "model = keras.Model(inputs=resnet_input_layer, outputs=resnet_block_output)  \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-relative",
   "metadata": {},
   "source": [
    "2-5. Ablation Study 실습 (3) VGG Complete Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-princess",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet(input_shape=(224,224,3),\n",
    "              num_block_list=[3, 4, 6, 3],\n",
    "              channel_list=[64,128,256,512],\n",
    "              num_classes=10, is_50=False): ## class for cats_n_dogs : 2\n",
    "    \n",
    "    input_layer = keras.layers.Input(shape=input_shape)  # input layer를 만들어둡니다.\n",
    "    x = input_layer\n",
    "\n",
    "    \n",
    "    ############\n",
    "    #CONV1\n",
    "    x = keras.layers.Conv2D(filters=64, kernel_size=(7,7), strides=2, name=f'conv1')(x)\n",
    "    x = keras.layers.MaxPooling2D(pool_size=(3,3), strides=2, name=f'initial_maxpooling')(x)\n",
    "    ############\n",
    "    \n",
    "    num_cnn = 2\n",
    "    \n",
    "    skip_connection= x\n",
    "\n",
    "    for i, (block, channel) in enumerate(zip(num_block_list, channel_list)):\n",
    "        for j in range(block):\n",
    "            if j!=0:\n",
    "                skip_connection=x\n",
    "            x = build_residual_block(\n",
    "                x,\n",
    "                num_cnn=num_cnn, \n",
    "                channel=channel,\n",
    "                block_num=j, chunk_num=i\n",
    "            )\n",
    "\n",
    "            print('x: ', x)\n",
    "            print('s: ', skip_connection)\n",
    "\n",
    "            print('chunk_num: {}, block_num: {}, add identity==================='.format(i, j))\n",
    "            if i==0:\n",
    "                x=tf.keras.layers.Add()([x, skip_connection])\n",
    "        print('--------------------reduce in size')\n",
    "        \n",
    "#         skip_connection= tf.keras.layers.ZeroPadding2D(padding=(1, 1))(x)\n",
    "#         if block_num!=1 and new_block==0:\n",
    "#             x = keras.layers.Conv2D(filters=channel,kernel_size=kernel_size,activation='relu',\n",
    "#                                     kernel_initializer='he_normal',padding='same', strides=2, name=f'block{block_num}_conv{cnn_num}')(x)\n",
    "            \n",
    "#         else:\n",
    "        \n",
    "\n",
    "# #         skip_connection= keras.layers.\n",
    "        \n",
    "    \n",
    "#     output = keras.layers.Flatten(name='flatten')(output)\n",
    "    output = keras.layers.Dense(1000, activation='relu', name='fc1')(x)\n",
    "    \n",
    "    model = keras.Model(\n",
    "        inputs=input_layer, \n",
    "        outputs=output\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-diagram",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet_34 = build_resnet(input_shape=(224,224,3), is_50=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-queensland",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resnet_34.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-louisville",
   "metadata": {},
   "source": [
    "2) VGG-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원하는 블록의 설계에 따라 매개변수로 리스트를 전달해 줍니다.\n",
    "vgg_19 = build_vgg(\n",
    "    num_cnn_list=[2,2,4,4,4],\n",
    "    channel_list=[64,128,256,512,512]\n",
    ")\n",
    "\n",
    "vgg_19.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-avenue",
   "metadata": {},
   "source": [
    "2-6. Ablation Study 실습 (4) VGG-16 vs VGG-19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'cifar10',\n",
    "    split=['train', 'test'],\n",
    "    as_supervised=True,\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    ")\n",
    "ds_train = apply_normalize_on_dataset(ds_train, batch_size=BATCH_SIZE)\n",
    "ds_test = apply_normalize_on_dataset(ds_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-triangle",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_16.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(lr=0.01, clipnorm=1.),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_16 = vgg_16.fit(\n",
    "    ds_train,\n",
    "    steps_per_epoch=int(ds_info.splits['train'].num_examples/BATCH_SIZE),\n",
    "    validation_steps=int(ds_info.splits['test'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_19.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(lr=0.01, clipnorm=1.),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_19 = vgg_19.fit(\n",
    "    ds_train,\n",
    "    steps_per_epoch=int(ds_info.splits['train'].num_examples/BATCH_SIZE),\n",
    "    validation_steps=int(ds_info.splits['test'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history_16.history['loss'], 'r')\n",
    "plt.plot(history_19.history['loss'], 'b')\n",
    "plt.title('Model training loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['vgg_16', 'vgg_19'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_16.history['val_accuracy'], 'r')\n",
    "plt.plot(history_19.history['val_accuracy'], 'b')\n",
    "plt.title('Model validation accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['vgg_16', 'vgg_19'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-medicare",
   "metadata": {},
   "source": [
    "2-7. 프로젝트: ResNet Ablation Study\n",
    "1) ResNet 기본 블록 구성하기\n",
    "이제 실전으로 돌아와서 ResNet-34와 ResNet-50 네트워크를 직접 만든다고 생각해 봅시다. 우선 ResNet-34와 ResNet-50에서 사용되는 블록의 공통점을 찾고 차이점을 찾아봅시다.\n",
    "\n",
    "Deep Residual Learning for Image Recognition(paper)\n",
    "빛과 같은 카이밍허님의 깃헙\n",
    "content img\n",
    "Q1. ResNet논문에 소개된 위 표에서, ResNet 34와 50에서 사용된 블록들의 공통점과 차이점을 비교해보고 그 특징을 정리해봅시다.\n",
    "\n",
    ".\n",
    "예시답안\n",
    "예시답안\n",
    "ResNet-34와 ResNet-50은 모두 conv block이라고 불리는 블록 구조를 각각 3, 4, 6, 3개씩 반복해서 쌓은 형태라는 공통점을 가지고 있습니다. 그러나 ResNet-34와 ResNet-50의 블록 내부 구성은 약간 다릅니다. ResNet-34의 경우 Block은 3x3 kernel인 Convolution layer로만 구성되어있지만, ResNet-50은 1x1 Convolution이 앞뒤로 붙어 더 많은 레이어를 한 블록 내에 가지게 됩니다.\n",
    "\n",
    "위의 퀴즈의 답을 어느 정도 스스로 찾아내셨다면 ResNet의 기본 블록, 또는 Residual 블록(residual block)이 어떻게 구성되어야 할지 감이 오셨을 것입니다. Learning by Doing 이라고 하죠! 이번에는 ResNet의 블록을 직접 만들어 봅시다! 혹시나 모델 내의 앞과 뒤에서 반복되지 않을 것 같은 부분은 함수로 구현하지 않아도 됩니다.\n",
    "\n",
    "우리가 지금 만들어야 하는 것은 블록을 생성하는 함수입니다. 처음이라 너무 막연하실 수 있겠지만 여러분들은 이미 몇 번의 경험이 있습니다.\n",
    "일단은 VGG에서도 블록을 생성하는 함수를 만들었습니다. ResNet이라 하더라도 아이디어의 기본 원리는 다르지 않습니다.\n",
    "\n",
    "그리고, 여러분들은 아마 이전에 VGG-16이나 ResNet-50 모델을 만들어서 훈련까지 시켜본 경험들이 있으실 것입니다. 코드를 스스로 구현한 것이 아니라 공개된 오픈소스를 활용해서 빠르게 구성했겠지만, 블록 생성 함수가 어떤 형태로 만들어지는지를 이미 경험해 보신 바 있을 테니 그것을 참고하셔도 도움이 될 것입니다.\n",
    "\n",
    "하지만 이번 단계에서는 가급적 ResNet 논문을 통해서 구현 방법에 대한 정보를 얻으시기를 권합니다. 논문만 보고 스스로 구현해 보는 경험을 통해 딥러닝 개발자로서의 내공과 자신감이 다져지게 될 것입니다.\n",
    "\n",
    "2) ResNet-34, ResNet-50 Complete Model\n",
    "ResNet 모델 구현 시 Sequential API나 Subclass API를 사용한다면, 그 과정에서 모델 단위로 기존의 코드를 재활용했을 때 model.summary() 호출 시 서브모델 내부의 레이어 구성이 생략되고 서브모델 단위로만 출력될 우려가 있습니다. 모델 구성만을 위해서는 그런 방법도 무방하지만, 가급적 이번 실습에서는 VGG 실습 예시에서처럼 Functional API 를 구성하는 방식을 사용할 것을 권합니다.\n",
    "\n",
    "ResNet-34\n",
    "VGG와 같이 블록을 만드는 함수를 사용해서 직접 전체 모델을 만들어 봅시다. ResNet-34와 ResNet-50의 차이에 따라 달라지는 구성(configuration)을 함수에 전달해서 같은 생성 함수 build_resnet()를 통해서 ResNet의 여러 가지 버전들을 모두 만들어 낼 수 있도록 해야 합니다.\n",
    "\n",
    "다음의 코드를 실행하면,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_50 = build_resnet(input_shape=(32, 32,3), is_50=True)\n",
    "resnet_50.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-newcastle",
   "metadata": {},
   "source": [
    "이러한 결과와 '비슷'하게 나와야 합니다. 참고하세요!\n",
    "ResNet-50은 구현마다 약간씩 다르게 나올 수 있습니다. 왜냐하면 Residual 블록의 Batch Normalization과 ReLU 레이어의 위치가 논문에 명시되지 않았기 때문이죠!\n",
    "\n",
    "하지만 ResNet을 고안한 4인방은 이에 대해 또 한번 논문을 씁니다. Residual 블록에 대해서 자세하게 씁니다. 이 논문을 읽어보면 오리지널 ResNet-50에 대한 힌트가 약.간. 있을 수도 있습니다~!\n",
    "\n",
    "Identity Mappings in Deep Residual Networks\n",
    "\n",
    "3) 일반 네트워크(plain network) 만들기\n",
    "블록 코드 수정하기\n",
    "우리는 앞에서 ResNet 모델을 구현했습니다. ResNet의 핵심 아이디어는 skip connection과 residual network기 때문에, ResNet의 효과를 보여주기 위해서는 skip connection이 없는 일반 네트워크(plain net)가 필요합니다. 위에서 ResNet 블록을 만들기 위한 함수를 그대로 활용해서 skip connection이 없는 블록을 만들 수 있도록 기능을 추가해 주세요!\n",
    "\n",
    "전체 함수 코드 수정하기\n",
    "이제 위에서 만든 블록 함수를 토대로 전체 네트워크를 만들 수 있도록 전체 네트워크 코드를 수정합시다. ResNet-50과 ResNet-34, 그리고 같은 레이어를 가지지만 skip connection이 없는 PlainNet-50과 PlainNet-34를 만들 수 있는 함수 build_plainnet()를 만들어 보세요. 이때 입력 이미지의 크기는 (224, 224, 3)으로 해주세요.\n",
    "\n",
    "4) ResNet-50 vs Plain-50 또는 ResNet-34 vs Plain-34\n",
    "Ablation Study\n",
    "이제 VGG-16, 19 예제와 같이 ResNet-50 vs Plain-50 또는 ResNet-34 vs Plain-34에 대해서 학습을 진행해 봅니다. 그리고 결과를 비교해 봅시다! ResNet은 많은 레이어와 Pooling을 거치므로 CIFAR-10에서는 오버피팅(overfitting)으로 잘 동작하지 않을 수 있습니다. 레이어가 많고 학습해야 할 변수(parameter)가 많은 데 비해, 데이터 수가 많지 않기 때문이지요. 224x224 픽셀 크기의 데이터셋을 찾아서 실험해 보도록 합시다. 학습은 끝까지 시키기엔 시간이 없으니 확인을 위한 정도의 epoch로 설정해 주세요.\n",
    "\n",
    "어떤 데이터셋을 사용하셔도 무방하지만, 얼른 떠오르는 것이 없다면 tensorflow-datasets에서 제공하는 cats_vs_dogs 데이터셋을 추천합니다. 아마 이 데이터셋도 다루어 보신 적이 있을 것입니다. Tensorflow에서 제공하는 데이터셋이므로 오늘 VGG 학습에 사용했던 CIFAR-10을 로딩하는 것과 같은 방법으로 활용하실 수 있습니다.\n",
    "\n",
    "시각화\n",
    "학습을 통해 만들어진 history를 matplotlib로 시각화하여 두 모델의 검증 정확도(validation accuracy)와 검증 손실(validation loss)이 어떻게 다른지 살펴봅시다.\n",
    "\n",
    "추가 실험\n",
    "시간이 남으면 아래 카탈로그를 보고, tensorflow-datasets의 지원하는 다른 데이터셋에 실험을 해봅시다.\n",
    "\n",
    "Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-difference",
   "metadata": {},
   "source": [
    "루브릭\n",
    "\n",
    "아래의 기준을 바탕으로 프로젝트를 평가합니다.\n",
    "\n",
    "평가문항\t상세기준\n",
    "1. ResNet-34, ResNet-50 모델 구현이 정상적으로 진행되었는가?\n",
    "\n",
    "블록함수 구현이 제대로 진행되었으며 구현한 모델의 summary가 예상된 형태로 출력되었다.\n",
    "2. 구현한 ResNet 모델을 활용하여 Image Classification 모델 훈련이 가능한가?\n",
    "\n",
    "cats_vs_dogs 데이터셋으로 학습시 몇 epoch동안 안정적으로 loss 감소가 진행 확인되었다.\n",
    "3. Ablation Study 결과가 바른 포맷으로 제출되었는가?\n",
    "\n",
    "ResNet-34, ResNet-50 각각 plain모델과 residual모델을 동일한 epoch만큼 학습시켰을 때의 validation accuracy 기준으로 Ablation Study 결과표가 작성되었다.\n",
    "프로젝트 업로드 (URL)\n",
    "\n",
    "GitHub URL을 입력하신 후 하단의 [성취하기] 버튼을 눌러주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-kruger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-energy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-engineer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-layer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
